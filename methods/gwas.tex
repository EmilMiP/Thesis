This section will briefly go over what a genome-wide association study is, some common considerations and models. A GWAS is usually performed on a single SNP at a time, rather than all SNPs at the same time. This is due to the computational cost of analysing data sets of the sizes that are usually present in biobanks and due to there being more SNPs than individuals. There are several potential models that can be used to analyse genotypes. One method is the Cochran-Armitage test \cite{cochran1954some,armitageTest}, which tests for independence in a $ 2\times3 $ contingency table. However, this test is not able to incorporate covariates to account for, e.g. population stratification. A regression based method is usually preferred, as it allows for covariates to be included. However, one downside of using regression models is the assumption that the SNP effects will be additive, which is not the case in the Cochran-Armitage test. The genetic data for regression is usually coded as $ AA = 0 $, $ Aa = 1 $, and $ aa = 2 $, where $ A $ is the major allele and $ a $ is the minor allele\cite{zeng2015statistical}. When restricting to only additive genetic effects, there is no difference between logistic or linear regression and the Cochran-Armitage test. The regression methods are then preferred over the Cochran-Armitage test as covariates can be included and linear regression is preferred over logistic regression, since it is more computationally efficient \cite{sikorska2013gwas,prive2019making}.


\subsection{Linear regression}
The simplest and most computationally efficient way to test association between a SNP and an outcome, even when the outcome is binary, is with linear regression. If we have $ N $ individuals where we observe a set of $ M $ SNPs, then the analysis of a single SNP can be described in the following way.

Let $ y $ denote the $ N\times1 $ vector of phenotypes for each individual, either binary or quantitative, $ X $ be the $ N \times (k+1) $ matrix containing $ k $ covariates and the intercept, $ G_j $ is a $ N\times 1 $ vector containing the $ j^{th} $ SNP, then the model is given by:

\begin{equation}\label{eq:baseGWAS}
y = \beta G_{j} +  X\gamma + \varepsilon
\end{equation}
Where $ \beta $ denotes the genetic effect size, $ \gamma $ denotes a $ (k + 1) \times 1$ vector of coefficients for the intercept and covariates, $ \varepsilon $ is a $ N \times 1 $ vector of independent normally distributed noise. When performing the regression, both $ y $ and $ G_j $ must be scaled to have mean $ 0 $ and variance $ 1 $. There is a computational cost involved in estimating the effect of the covariates, and they are not of any interest when performing GWAS. Therefore, the most efficient way to account for the covariates without directly calculating their effect in each regression is to project them out of the predictor and the response of interest in \cref{eq:baseGWAS} \cite{sikorska2013gwas}.

The least squares solution to \cref{eq:baseGWAS} is given by 
\begin{equation}
\begin{pmatrix}
G_j^T G_j & G_j^T X \\
X^T G_j & X^T X
\end{pmatrix}
\begin{pmatrix}
\hat{\beta} \\
\hat{\gamma}
\end{pmatrix} = 
\begin{pmatrix}
G_j^T y \\
X^T y
\end{pmatrix}
\end{equation}
where $ \hat{\beta} $ and $ \hat{\gamma} $ are solutions. The least squares equations represent the following equations

\begin{align}
G_j^T G_j\hat{\beta} +  G_j^T X \hat{\gamma} =&  G_j^T y  \label{eq:covregress1}\\ 
X^T G_j \hat{\beta} + X^T X \hat{\gamma} =&  X^Ty \label{eq:covregress2}
\end{align}
From here we isolate $ \hat{\gamma} $ in \cref{eq:covregress2} and get $ \hat{\gamma} = (X^TX)^{-1}(X^Ty - \hat{\beta} X^TG_j) $, which is then inserted in to \cref{eq:covregress1} 

\begin{equation}
G^T_j y = G_j^TG_j + G_j^TX (X^TX)^{-1}(X^Ty - \hat{\beta} X^TG_j)
\end{equation}
By isolating terms related to $ y $ on the left hand side and term related to $ \hat{\beta} $ on the right hand side we get the following

\begin{equation} \label{eq:GWASprojection}
G_j^T(y - X(X^TX)^{-1}X^Ty) = G_j^T(G_j - X(X^TX)^{-1}X^TG_j) \hat{\beta}
\end{equation}
Recall that $ X(X^TX)^{-1}X^T $ denotes the projection onto the space spanned by the matrix $ X $. From here, we will introduce transformations given by 
\begin{align}
	y^\ast = y - X(X^TX)^{-1}X^Ty & & & G_j^{\ast} = G_j - X(X^TX)^{-1}X^TG_j
\end{align}
The transformations remove the effect of the covariates in $ X $ from the response and predictor of interest. Using the properties of projections, \cref{eq:GWASprojection}, and the transformations, we find that 

\begin{equation}
\left( G_j^{\ast} \right)^T G^{\ast} \hat{\beta} = G_j^T G_j^{\ast} \hat{\beta} \stackrel{\ref{eq:GWASprojection}}{=} G^T y^{\ast} = \left( G_j^{\ast} \right)^T y^{\ast}
\end{equation}
The normal equations for systems of equations of the form $ Ax=b $ say that $ \hat{\beta} $ is a solution to a new univariate regression given by

\begin{align}\label{eq:univarGWAS}
y^\ast = \hat{\beta} G_j^{\ast} + \varepsilon&   &\text{with simplified solution}&  &\hat{\beta} = \dfrac{\left( G_j^{\ast} \right)^T y^{\ast}}{\left( G_j^{\ast} \right)^T G^{\ast}}
\end{align}
With the projection, the effect of the covariates have been removed form the outcome and the prediction, i.e. the phenotype and the genotype. The calculations for the projection matrix only has to be performed once. Accounting for the covariates effect in the phenotype also only has to be done once. While the projection matrix calculations do not have to be repeated, the removal of the covariate's effect on the SNP has to be done for each SNP separately.

The hypothesis being tested is then $ H_0: \beta = 0 $ against $ H_A: \beta \neq 0 $. One of the most common ways to perform the test is with a Wald test $ Z = \hat{\beta}/\text{se}(\hat{\beta}) \sim N(0,1)$. 

% tutorial paper \cite{balding2006tutorial}
\subsection{Dealing with population structure}
Population structure is a term that covers several types of potential biases in a GWAS. These biases can result in spurious associations between SNPs and phenotypes, when there is no true association. The most common reasons for population structure in genotype data is due to \textit{population stratification}, \textit{related individuals}, and two or more \textit{ancestries} in the data. These sources of bias all result in the same underlying problem, namely artificial differences or similarities between a case and control group, which either creates a spurious or masks a true association. 

\subsubsection{Population stratification}
Within a population of individuals, it has been shown that there can be subpopulations where allele frequencies differ between subpopulations. As mentioned above, it can cause artificial differences or similarities between the subpopulations when performing associations tests. One example of a spurious association driven by population stratification is the chopstick gene, which allegedly accounted for half of the variance in being able to eat with chopsticks.\cite{marees2018tutorial} 

A common and simple solution to account for population structure is by performing a PCA on the genotypes and including the first, e.g. 20 PCs, as covariates in the association analysis \cite{price2006principal,price2010new}.

\subsubsection{Relatedness}
Similar to population structure, relatedness is a common reason to spurious associations. The mechanism behind why relatedness leads to these spurious associations is a little different. If related individuals are in the same analysis, then some individuals are more alike than one would expect if they were drawn at random. Due to this, variances are likely biased downwards, which leads to inflated test statistics, since many associations tests are Wald tests and Wald tests are calculated as the effect estimate divided by the standard error. 

There are two common ways to deal with relatedness in a GWAS setting. The first and simplest way is to identify the related individuals and removing them from the analysis. This is effective, but has the downside of reducing the sample size, and it is likely to not work if the analysed data consist of genotyped families. The second and more involved way is to include the relatedness in the model being used for association. In a regression setting, the most common way to account for the relatedness is by using a linear mixed model, where a random effect is added. The random effect is able to account for covariance structure, which is how relatedness affects associations with higher than expected observations.\cite{yu2006unified, kang2008efficient}

There are several ways to identify the related individuals, with the two most common ways being the genetic relatedness matrix and identity by descent. The GRM is simply the correlation between two individual's (scaled) genotypes, where a value of $ 1 $ means monozygotic twins, $ 0.5 $ is a parent-offspring relationship, etc.. If filtering is performed prior to the association test, the relatedness threshold is usually set to $ 2^{-2.5} \approx 0.177 $ when removing $ 2^{nd} $ degree relatives or closer, or $ 2^{-3.5} \approx 0.088 $ when removing $ 3^{rd} $ degree relatives, etc. The method for filtering for relatedness is similar when using IBD, however the values are between $ 0.5 $ and $ 0 $ instead of $ 1 $ and $ 0 $. To get the same level of relatedness filtering with IBD as one would get with the GRM, the thresholds should be shifted by a factor of $ 2^{-1} $ and will have thresholds $ 2^{-3.5} $ and $ 2^{-4.5} $, respectively. An IBD approach for identifying relatedness is provided by the KING software\cite{manichaikul2010robust}, and a GRM based approach is provided by the GCTA software \cite{yang2011gcta}.


\subsubsection{Ancestries}   
Analysing different ancestries together in a GWAS is not commonly done. This is due to different ancestries may be different minor allele frequencies for certain SNPs, altogether different variants on certain positions, etc., which complicates a combined analysis\cite{helgason2005icelandic}. Therefore, they most common way to deal with different ancestries in a genotyped data set is to identify a genetically homogenous subset and perform the association analysis in the desired homogeneous subpopulation. There have been methods proposed that can account for ancestry such as tractor, but they have not been widely adopted \cite{atkinson2021tractor}.

A homogenous subpopulation is most commonly identified by performing a PCA on all the available individuals and calculating the Mahalanobis distance on the first, e.g. 20 PCs, and removing anyone above a certain threshold\cite{prive2020efficient}. 
